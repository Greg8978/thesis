\ifdefined\included
\else
\documentclass[a4paper,11pt,twoside]{StyleThese}
\include{formatAndDefs}
\sloppy
\begin{document}
\fi


\chapter*{Conclusion et Perspectives}
\addstarredchapter{Conclusion et Perspectives} %Sinon cela n'apparait pas dans la table des matières

\section{Conclusion}
Ce manuscrit de thèse rapporte à travers cinq chapitres comment il est possible d'acquérir et d'utiliser des données contextuelles de différents niveaux d'abstraction pour permettre d'améliorer l'interaction homme-robot dans différents domaines tel que la dialogue situé, l'assistance proactive, la génération de plan, l'exécution de tâches collaboratives...

Dans le chapitre \ref{chapter1} nous avons montrer comment il est possible de mettre en place une architecture modulaire basée l'agrégation de données capteurs et sur certains raisonnements pour acquérir et maintenir un état du monde tridimensionnel correspondant à la représentation du monde réel tel qu'il est perçu et inféré (grâce à une gestion d'hypothèses) par le robot. Basé sur cette représentation tridimensionnelle, nous montrons comment les différents modules de l'architecture permettent de générer des \textit{faits} constituant une représentation symbolique du monde. Ces faits sont centralisés par une base de donnée temporelle qui possède une table permettant de garder en mémoire les faits passés et les transitions survenues. Nous présentons également dans ce premier chapitre TOASTER, une infrastructure logicielle modulaire Open-Source implémentant les principes et modèles énoncés.
Deux exemples d'expérimentations utilisant l'infrastructure logicielle TOASTER comme module d'estimation de la situation ont été présentés comme exemple d'utilisation possible.

Dans le chapitre \ref{chapter2}, nous montrons expliquons brièvement les concepts de prise de perspective perceptuelle et conceptuelle. Nous montrons également que ces capacités sont importantes dans les interactions sociales humaines. Nous présentons en suite comment, à partir de calculs géométriques il nous est possible de doter le système robotique de prise de perspective perceptuelle afin que le robot puisse savoir ce qui est perceptible ou atteignable par l'homme.
Basé sur cette prise de perspective perceptuelle et sur un raisonnement permettant de gérer la mise à jour des croyances des agents, nous avons montrer qu'il est possible de maintenir un état de croyance distinct pour chaque agent présents dans la scène. Cette gestion des croyances permet de doter le robot de la capacité de prise de perspective conceptuelle.
Pour montrer la capacité de notre robot à se mettre à la place d'un autre agent et de raisonner sur ses croyances, nous avons fait passer deux tests à notre robot. Le premier étant le test connu dans la littérature de la philosophie du développement sous le nom de test de Sally et Anne. Le second est un scénario d'interaction où deux hommes manipulent des objets en présence du robot.

Le chapitre \ref{chapter3} décrit comment les données contextuelles et la capacité de prise de perspective permet de mettre en place un dialogue situé de qualité. Nous avons montré comment les données contextuelles de différents niveaux d'abstraction (position, distance, représentation symbolique, prise de perspective) sont utilisés tout au long du processus de dialogue (compréhension de la parole, interprétation des gestes de l'homme, identification du référent, choix de la politique par la couche décisionnelle, choix de la modalité de sortie et modulation de la voix, exploration et exécution de la tâche).
Nous présentons notamment une étude menée sur simulateur qui a permis de montrer l'utilité de la prise de perspective conceptuelle pour rendre le dialogue plus efficace et plus précis. Nous présentons également une expérimentation menée sur plateforme robotique qui illustre divers stratégies prenant en compte le contexte et l'état mental de l'homme pour adapter l'exécution de la tâche.

Le chapitre \ref{chapter4} présente comment, en utilisant le contexte et l'état mental de l'homme, il est possible d'interpréter les actions de l'homme afin d'en déduire son intention. Nous avons montré comment cette information permet au robot d'agir de façon proactive pour prévenir l'homme dans le cas où celui-ci effectue une action non optimale par rapport à son objectif à cause de croyances erronées. Il est également possible pour le robot d'aider l'homme à accomplir son but sans que celui-ci ait à exprimer explicitement un besoin ou une requête. Cela donne au robot un aspect proactif. Nous avons également présenté une étude en ligne où les performances de notre système ont été comparées aux performances d'humains pour reconnaître l'intention d'un tiers. Cette étude a permis de montrer que dans la plupart des situations, notre système avait une estimation comparable à l'homme.

Enfin, dans le chapitre \ref{chapter5}, nous avons présenté nos travaux pour adapter le comportement du robot à l'expertise humaine concernant les divers tâches contenues dans un plan collaboratif. Nous avons mis en place une modélisation de l'état de connaissance de l'homme concernant les tâches qui peuvent être présentes dans un plan collaboratif. En utilisant cette modélisation, le robot est capable d'adapter la génération de plan à l'expertise humaine. Lors de l'exécution du plan, le robot est également capable d'adapter le niveau d'explication donné à l'homme en s'appuyant sur la structure hiérarchique du plan pour décrire plus ou moins en détails les tâches à accomplir. De même, cette structure hiérarchique et le niveau de connaissance de l'homme sont également utilisées pour adapter le niveau de surveillance du robot sur les tâches accomplies par l'homme. Nous avons effectué une étude utilisateur en ligne afin de comparer l'adaptabilité de notre système aux connaissances de l'homme avec un système standard. Les résultats ont permis de montrer que l'adaptation du système était bien perçue par les utilisateurs.


\section{Améliorations et travaux à venir}

%TODO
%liste des améliorations
\ifdefined\included
\else
\bibliographystyle{acm}
\bibliography{These}
\end{document}
\fi